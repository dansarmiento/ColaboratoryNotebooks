{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorflowKerasSimple.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPjsnKa47wZPUQpw/DXq3Ay",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dansarmiento/ColaboratoryNotebooks/blob/main/TensorflowKerasSimple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PS0FniODDE7l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from random import randint\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = []\n",
        "train_samples = []"
      ],
      "metadata": {
        "id": "p-WaAOCZDSQd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "example data:\n",
        "experimental drug tested on people age 13 to 100\n",
        "trial had 2100 participants, half under 65, half older\n",
        "around 95% of older had side effects\n",
        "around 95% of younger did not have side effects\n"
      ],
      "metadata": {
        "id": "0lo3wQ_MDaNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets to work with\n",
        "\n",
        "for i in range(50):\n",
        "  # the 5% of younger ppl that didn't have side effects\n",
        "  random_younger = randint(13,64)\n",
        "  train_samples.append(random_younger)\n",
        "  train_labels.append(1)\n",
        "\n",
        "  # the 5% of older that did not have side effects\n",
        "  random_older = randint(65,100)\n",
        "  train_samples.append(random_older)\n",
        "  train_labels.append(0)\n",
        "\n",
        "for i in range(1000):\n",
        "  # the 95% of younger who did not have side effects\n",
        "  random_younger = randint(13,64)\n",
        "  train_samples.append(random_younger)\n",
        "  train_labels.append(0)\n",
        "\n",
        "  # the 95% of older who did have side effects\n",
        "  random_older = randint(65,100)\n",
        "  train_samples.append(random_older)\n",
        "  train_labels.append(1)"
      ],
      "metadata": {
        "id": "HuzIXLUND0JX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = np.array(train_labels)\n",
        "train_samples = np.array(train_samples)\n",
        "train_labels, train_samples = shuffle(train_labels, train_samples)"
      ],
      "metadata": {
        "id": "yqfPoBXuFP9A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# squish the values between 0 and 1 for the machine learning to work\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))"
      ],
      "metadata": {
        "id": "yNuwlrF3Nz9Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense \n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy "
      ],
      "metadata": {
        "id": "xbDTePd8OaBD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential([\n",
        "    Dense(units=16, input_shape=(1,), activation='relu'),   # units are arbitrary, look up relu\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=2, activation='softmax')     # last layer has the options available, side effects or none\n",
        "])                # softmax function gives probability for each class\n"
      ],
      "metadata": {
        "id": "AJIA5E1uQ18S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XWyXmzISyir",
        "outputId": "0fcc2c2f-4cf3-4a2e-c9e0-07545ce0dcf4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 16)                32        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                544       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "# this prepares model for training\n",
        "# parameters in the model compiler are optimizer, loss, and metrics"
      ],
      "metadata": {
        "id": "8OFBKVLpSzzL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, shuffle=True, verbose=2)\n",
        "# batch size is how many samples per batch, epochs means model trains on all data 30 times\n",
        "# shuffle is default, we want the model to be able to generalize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkF9ZWnsVCtK",
        "outputId": "ff8c350f-4686-4e7c-dd2c-b1a9f0cf678f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "210/210 - 2s - loss: 0.6862 - accuracy: 0.6229 - 2s/epoch - 8ms/step\n",
            "Epoch 2/30\n",
            "210/210 - 0s - loss: 0.6569 - accuracy: 0.6457 - 373ms/epoch - 2ms/step\n",
            "Epoch 3/30\n",
            "210/210 - 0s - loss: 0.6299 - accuracy: 0.6719 - 475ms/epoch - 2ms/step\n",
            "Epoch 4/30\n",
            "210/210 - 0s - loss: 0.5988 - accuracy: 0.7438 - 436ms/epoch - 2ms/step\n",
            "Epoch 5/30\n",
            "210/210 - 0s - loss: 0.5672 - accuracy: 0.7705 - 281ms/epoch - 1ms/step\n",
            "Epoch 6/30\n",
            "210/210 - 0s - loss: 0.5366 - accuracy: 0.8043 - 260ms/epoch - 1ms/step\n",
            "Epoch 7/30\n",
            "210/210 - 0s - loss: 0.5064 - accuracy: 0.8276 - 252ms/epoch - 1ms/step\n",
            "Epoch 8/30\n",
            "210/210 - 0s - loss: 0.4768 - accuracy: 0.8481 - 247ms/epoch - 1ms/step\n",
            "Epoch 9/30\n",
            "210/210 - 0s - loss: 0.4485 - accuracy: 0.8681 - 265ms/epoch - 1ms/step\n",
            "Epoch 10/30\n",
            "210/210 - 0s - loss: 0.4223 - accuracy: 0.8843 - 251ms/epoch - 1ms/step\n",
            "Epoch 11/30\n",
            "210/210 - 0s - loss: 0.3987 - accuracy: 0.8929 - 255ms/epoch - 1ms/step\n",
            "Epoch 12/30\n",
            "210/210 - 0s - loss: 0.3780 - accuracy: 0.8957 - 260ms/epoch - 1ms/step\n",
            "Epoch 13/30\n",
            "210/210 - 0s - loss: 0.3600 - accuracy: 0.9048 - 260ms/epoch - 1ms/step\n",
            "Epoch 14/30\n",
            "210/210 - 0s - loss: 0.3444 - accuracy: 0.9076 - 261ms/epoch - 1ms/step\n",
            "Epoch 15/30\n",
            "210/210 - 0s - loss: 0.3312 - accuracy: 0.9114 - 239ms/epoch - 1ms/step\n",
            "Epoch 16/30\n",
            "210/210 - 0s - loss: 0.3199 - accuracy: 0.9190 - 243ms/epoch - 1ms/step\n",
            "Epoch 17/30\n",
            "210/210 - 0s - loss: 0.3102 - accuracy: 0.9181 - 254ms/epoch - 1ms/step\n",
            "Epoch 18/30\n",
            "210/210 - 0s - loss: 0.3019 - accuracy: 0.9224 - 255ms/epoch - 1ms/step\n",
            "Epoch 19/30\n",
            "210/210 - 0s - loss: 0.2949 - accuracy: 0.9238 - 248ms/epoch - 1ms/step\n",
            "Epoch 20/30\n",
            "210/210 - 0s - loss: 0.2889 - accuracy: 0.9286 - 248ms/epoch - 1ms/step\n",
            "Epoch 21/30\n",
            "210/210 - 0s - loss: 0.2836 - accuracy: 0.9319 - 273ms/epoch - 1ms/step\n",
            "Epoch 22/30\n",
            "210/210 - 0s - loss: 0.2794 - accuracy: 0.9262 - 248ms/epoch - 1ms/step\n",
            "Epoch 23/30\n",
            "210/210 - 0s - loss: 0.2756 - accuracy: 0.9300 - 247ms/epoch - 1ms/step\n",
            "Epoch 24/30\n",
            "210/210 - 0s - loss: 0.2723 - accuracy: 0.9324 - 249ms/epoch - 1ms/step\n",
            "Epoch 25/30\n",
            "210/210 - 0s - loss: 0.2694 - accuracy: 0.9324 - 260ms/epoch - 1ms/step\n",
            "Epoch 26/30\n",
            "210/210 - 0s - loss: 0.2668 - accuracy: 0.9329 - 254ms/epoch - 1ms/step\n",
            "Epoch 27/30\n",
            "210/210 - 0s - loss: 0.2648 - accuracy: 0.9362 - 239ms/epoch - 1ms/step\n",
            "Epoch 28/30\n",
            "210/210 - 0s - loss: 0.2627 - accuracy: 0.9376 - 252ms/epoch - 1ms/step\n",
            "Epoch 29/30\n",
            "210/210 - 0s - loss: 0.2609 - accuracy: 0.9376 - 254ms/epoch - 1ms/step\n",
            "Epoch 30/30\n",
            "210/210 - 0s - loss: 0.2593 - accuracy: 0.9357 - 247ms/epoch - 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fab05c226d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QJYLCz_-Vopg"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}